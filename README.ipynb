{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation Systems To Consider\n",
    "\n",
    "1. **Significant Terms** -> It uses the concept of foreground (the search query) and background (the overall dataset) and uses a custom scoring system that detects statistically significant patterns. Because of the way that the documents are modeled (one per user and each containing the user's past item interactions), it then recommends next set of items. See Simple Significant Terms.ipynb file for this system.\n",
    "\n",
    "2. **Generalized Significant Terms** -> Here, we also account for different types of signals and interaction counts. See Generalized Significant Terms.ipynb file for this system (This is WIP right now)\n",
    "\n",
    "Other models that I've considered but discarded:\n",
    "\n",
    "1. Using Bayes' model of scoring (same idea but a different scoring function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations Search: POC\n",
    "\n",
    "This document presents the outline of the recommendations search and contains utils to setup the data index as well as clean it up.\n",
    "\n",
    "### Goal\n",
    "\n",
    "Recommend the next item to a user based on the signals of past interactions of theirs and other users similar to them.\n",
    "\n",
    "\n",
    "### Data Model and Assumptions\n",
    "\n",
    "\n",
    "1. We will start with a single signal (aka event): `visit`. We will generalize this later to multiple types of signals. When generalizing this, we will have to factor in a weight for each signal.\n",
    "2. We will model the data as an index of documents. Each document contains the past items interaction history of a particular user. Total documents = total users.\n",
    "3. ElasticSearch specific assumption: We will use the `nested` type for the items field. (We don't want the items to be flattened as an array which is what ElasticSearch does by default).\n",
    "4. In the simple model, we are not doing any rollups (e.g. interaction count per item) at the time of data insertion. We will do this with the generalized model.\n",
    "5. We're not storing a timestamp of interaction right now.\n",
    "\n",
    "\n",
    "An example document in our index would look like this:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"user_id\": \"1\",\n",
    "    \"items\": [\n",
    "        {\n",
    "            \"item\": \"a\"\n",
    "        },\n",
    "        {\n",
    "            \"item\": \"b\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Evaluate\n",
    "\n",
    "Use the following notebook for evaluation: [Evaluation.ipynb](/Evaluation.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
