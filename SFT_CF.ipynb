{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Significant Terms\n",
    "\n",
    "Here, we model the recommendations using significant terms aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'url' (str)\n",
      "Stored 'headers' (dict)\n"
     ]
    }
   ],
   "source": [
    "# We will define some persistent variables that we will use everywhere over here. Always run this script first\n",
    "\n",
    "# you may want to update the value below to something like 'http://localhost:9200/search_recommendations' for testing locally\n",
    "url = 'http://localhost:9200/events'\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "%store url\n",
    "%store headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"acknowledged\":true}'\n"
     ]
    }
   ],
   "source": [
    "# (optional) deletes the index\n",
    "import requests\n",
    "\n",
    "response = requests.request(\"DELETE\", url)\n",
    "print(response.text.encode('utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"acknowledged\": true,\n",
      "  \"shards_acknowledged\": true,\n",
      "  \"index\": \"events\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Here's the script to create a fresh index with the mapping\n",
    "import requests\n",
    "import json \n",
    "\n",
    "data = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"agent\": {\n",
    "                \"type\": \"keyword\"\n",
    "            },\n",
    "            \"buy\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"target\": {\n",
    "                        \"type\": \"keyword\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.request(\"PUT\", url, headers=headers, data=json.dumps(data))\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"took\": 48,\n",
      "  \"errors\": false,\n",
      "  \"items\": [\n",
      "    {\n",
      "      \"index\": {\n",
      "        \"_index\": \"events\",\n",
      "        \"_type\": \"_doc\",\n",
      "        \"_id\": \"W5wxhHIByTqzuCc4QxQj\",\n",
      "        \"_version\": 1,\n",
      "        \"result\": \"created\",\n",
      "        \"_shards\": {\n",
      "          \"total\": 2,\n",
      "          \"successful\": 1,\n",
      "          \"failed\": 0\n",
      "        },\n",
      "        \"_seq_no\": 0,\n",
      "        \"_primary_term\": 1,\n",
      "        \"status\": 201\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"index\": {\n",
      "        \"_index\": \"events\",\n",
      "        \"_type\": \"_doc\",\n",
      "        \"_id\": \"XJwxhHIByTqzuCc4QxQj\",\n",
      "        \"_version\": 1,\n",
      "        \"result\": \"created\",\n",
      "        \"_shards\": {\n",
      "          \"total\": 2,\n",
      "          \"successful\": 1,\n",
      "          \"failed\": 0\n",
      "        },\n",
      "        \"_seq_no\": 1,\n",
      "        \"_primary_term\": 1,\n",
      "        \"status\": 201\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"index\": {\n",
      "        \"_index\": \"events\",\n",
      "        \"_type\": \"_doc\",\n",
      "        \"_id\": \"XZwxhHIByTqzuCc4QxQj\",\n",
      "        \"_version\": 1,\n",
      "        \"result\": \"created\",\n",
      "        \"_shards\": {\n",
      "          \"total\": 2,\n",
      "          \"successful\": 1,\n",
      "          \"failed\": 0\n",
      "        },\n",
      "        \"_seq_no\": 2,\n",
      "        \"_primary_term\": 1,\n",
      "        \"status\": 201\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"index\": {\n",
      "        \"_index\": \"events\",\n",
      "        \"_type\": \"_doc\",\n",
      "        \"_id\": \"XpwxhHIByTqzuCc4QxQj\",\n",
      "        \"_version\": 1,\n",
      "        \"result\": \"created\",\n",
      "        \"_shards\": {\n",
      "          \"total\": 2,\n",
      "          \"successful\": 1,\n",
      "          \"failed\": 0\n",
      "        },\n",
      "        \"_seq_no\": 3,\n",
      "        \"_primary_term\": 1,\n",
      "        \"status\": 201\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"index\": {\n",
      "        \"_index\": \"events\",\n",
      "        \"_type\": \"_doc\",\n",
      "        \"_id\": \"X5wxhHIByTqzuCc4QxQj\",\n",
      "        \"_version\": 1,\n",
      "        \"result\": \"created\",\n",
      "        \"_shards\": {\n",
      "          \"total\": 2,\n",
      "          \"successful\": 1,\n",
      "          \"failed\": 0\n",
      "        },\n",
      "        \"_seq_no\": 4,\n",
      "        \"_primary_term\": 1,\n",
      "        \"status\": 201\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# (only run once) Here's the script to populate some qualitative data in the index\n",
    "#\n",
    "# We will use the following data:\n",
    "# \n",
    "#| agent~target | a | b | c | d | e |\n",
    "#|--------------|---|---|---|---|---|\n",
    "#| 1            | + |   | + | + |   |\n",
    "#| 2            | + |   |   | + |   |\n",
    "#| 3            | + |   |   | + | + |\n",
    "#| 4            |   | + |   |   | + |\n",
    "#| 5            |   |   |   |   | + |\n",
    "\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "data = '''\n",
    "{\"index\": {}}\n",
    "{ \"agent\": \"1\", \"buy.target\": [ \"a\", \"c\", \"d\" ] }\n",
    "{\"index\": {}}\n",
    "{ \"agent\": \"2\", \"buy.target\": [ \"a\", \"d\" ] }\n",
    "{\"index\": {}}\n",
    "{ \"agent\": \"3\", \"buy.target\": [ \"a\", \"d\", \"e\" ] }\n",
    "{\"index\": {}}\n",
    "{ \"agent\": \"4\", \"buy.target\": [ \"b\", \"e\" ] }\n",
    "{\"index\": {}}\n",
    "{ \"agent\": \"5\", \"buy.target\": [ \"a\", \"e\" ] }\n",
    "'''\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/x-ndjson'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url+'/_bulk', headers=headers, data=data)\n",
    "print(json.dumps(response.json(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  \"a\",\n",
      "  \"c\",\n",
      "  \"d\"\n",
      "]\n",
      "recommended target list via S.F.T (debug): [\n",
      "  {\n",
      "    \"key\": \"a\",\n",
      "    \"doc_count\": 4,\n",
      "    \"score\": 0.24999999999999994,\n",
      "    \"bg_count\": 4\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"d\",\n",
      "    \"doc_count\": 3,\n",
      "    \"score\": 0.18750000000000003,\n",
      "    \"bg_count\": 3\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"c\",\n",
      "    \"doc_count\": 1,\n",
      "    \"score\": 0.062499999999999986,\n",
      "    \"bg_count\": 1\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"e\",\n",
      "    \"doc_count\": 2,\n",
      "    \"score\": 8.333333333333334e-05,\n",
      "    \"bg_count\": 3\n",
      "  }\n",
      "]\n",
      "recommended target list via terms agg (debug): [\n",
      "  {\n",
      "    \"key\": \"b\",\n",
      "    \"doc_count\": 1\n",
      "  },\n",
      "  {\n",
      "    \"key\": \"e\",\n",
      "    \"doc_count\": 1\n",
      "  }\n",
      "]\n",
      "final recommendations: ['e', 'b']\n"
     ]
    }
   ],
   "source": [
    "# Recommend the next targets to buy\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "#input\n",
    "agent=\"1\"\n",
    "\n",
    "# returns past interaction targets. They help in informing both\n",
    "# the foreground set (i.e. correlated targets) as well as how to\n",
    "# finally account for the recommendations\n",
    "def get_past_interactions(agent_id):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"term\": {\n",
    "                \"agent\": agent_id\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = requests.request(\"GET\", url+\"/_search\", headers=headers, data=json.dumps(query))\n",
    "    response_hits = response.json()['hits']['hits']\n",
    "    if len(response_hits) == 1:\n",
    "        targets = response_hits[0]['_source']['buy.target']\n",
    "    print(json.dumps(targets, indent=2))\n",
    "    return targets\n",
    "\n",
    "# returns recommended interactions. We use the S.F.T. aggs here to mimic\n",
    "# Collaborative Filtering.\n",
    "# Foreground Set = documents that contain correlated targets\n",
    "# Background Set = all the documents\n",
    "# S.F.T. uses these two sets to find statistically significant targets -> i.e. targets that behave in a statistically interesting way in foreground relative to the background.\n",
    "# The default scoring algorithm looks like (foreground_freq / background_freq) * (foreground_freq - background_freq).\n",
    "# We will modify it slightly so that documents with foreground_freq < background_freq (negative scores) still return albeit with a very low score.\n",
    "def recommended_interactions(agent_id, past_interactions):\n",
    "    # tunable parameters\n",
    "    required_matches=1\n",
    "    \n",
    "    query = {\n",
    "        \"size\": 0,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"should\": {\n",
    "                    \"terms\": {\n",
    "                        \"buy.target\": past_interactions\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"aggs\": {\n",
    "            \"sft\": {\n",
    "                \"significant_terms\": {\n",
    "                    \"field\": \"buy.target\",\n",
    "                    \"min_doc_count\": 1,\n",
    "                    \"script_heuristic\": {\n",
    "                        \"script\": {\n",
    "                            \"lang\": \"painless\",\n",
    "                            \"source\": \"\"\"\n",
    "                                double ff = 1.0*(params._subset_freq/Math.max(1, 1.0*params._subset_size));\n",
    "                                double bf = 1.0*(params._superset_freq/Math.max(1, 1.0*params._superset_size));\n",
    "                                return (ff/bf)*Math.max((ff - bf), 0.0001)\"\"\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    response = requests.request(\"GET\", url+'/_search', headers=headers, data=json.dumps(query))\n",
    "    recommended_target_list = response.json()['aggregations']['sft']['buckets']\n",
    "    print(f'recommended target list via S.F.T (debug): {json.dumps(recommended_target_list, indent=2)}')\n",
    "    if len(recommended_target_list) > 0:\n",
    "        recommended_targets = set(map(lambda x: x['key'], recommended_target_list))\n",
    "        new_recommended_targets = list(recommended_targets - set(past_interactions))\n",
    "    return new_recommended_targets\n",
    "\n",
    "# returns most popular target recommendations from those outside of the agent's past interactions\n",
    "# and ones that are already not recommended by sft.\n",
    "def get_popular_items(agent, past_interactions, sft_recommendations):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must_not\": {\n",
    "                    \"terms\": {\n",
    "                        \"buy.target\": past_interactions\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"aggs\": {\n",
    "            \"popular_targets\": {\n",
    "                \"terms\": {\n",
    "                    \"field\": \"buy.target\",\n",
    "                    \"size\": 10\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    response = requests.request(\"GET\", url+'/_search', headers=headers, data=json.dumps(query))\n",
    "    popular_buckets = response.json()['aggregations']['popular_targets']['buckets']\n",
    "    print(f'recommended target list via terms agg (debug): {json.dumps(popular_buckets, indent=2)}')\n",
    "    popular_targets = list(set(map(lambda x: x['key'], popular_buckets)) - set(past_interactions) - set(sft_recommendations))\n",
    "    return popular_targets\n",
    "\n",
    "past_interactions = get_past_interactions(agent)\n",
    "sft_recommendations = recommended_interactions(agent, past_interactions)\n",
    "if len(sft_recommendations) < 3:\n",
    "    popular_recommendations = get_popular_items(agent, past_interactions, sft_recommendations)\n",
    "    \n",
    "\n",
    "print(f'final recommendations: {sft_recommendations + popular_recommendations}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
